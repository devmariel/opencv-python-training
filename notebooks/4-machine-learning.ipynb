{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = cv2.imread('../datasets/fashion.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (fashion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [np.hsplit(row, 30) for row in np.vsplit(fashion, 30)]\n",
    "\n",
    "images = np.array(images, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = images[:, :15].reshape (-1, (28 * 28))\n",
    "print (train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = images[:, 15:30].reshape (-1, (28 * 28))\n",
    "print (test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = cv2.ml.KNearest_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "#convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "\n",
    "#count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "#compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Accuracy: {}'. format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[16, 2], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "print (mnist.shape)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype = np.float32)\n",
    "train_features = images[:, :50].reshape (-1, (20 * 20))\n",
    "print (train_features.shape)\n",
    "test_features = images[:, 50:100].reshape (-1, (20 * 20))\n",
    "print (test_features.shape)\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "knn = cv2.ml.KNearest_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.ml.SVM_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "print ('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with MEAN NORMALIZATION\n",
    "fashion = cv2.imread('../datasets/fashion.png', 0)\n",
    "print (fashion.shape)\n",
    "images = [np.hsplit(row, 30) for row in np.vsplit(fashion, 30)]\n",
    "images = np.array(images, dtype = np.float32)\n",
    "train_features = images[:, :15].reshape (-1, (28 * 28))\n",
    "print (train_features.shape)\n",
    "test_features = images[:, 15:30].reshape (-1, (28 * 28))\n",
    "print (test_features.shape)\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "train_features -= np.mean(train_features, axis = 0)\n",
    "test_features -= np.mean(train_features, axis = 0)\n",
    "knn = cv2.ml.KNearest_create()\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "result = model.predict(test_features)\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "print ('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = cv2.imread('../datasets/fashion.png', 0)\n",
    "print (fashion.shape)\n",
    "images = [np.hsplit(row, 30) for row in np.vsplit(fashion, 30)]\n",
    "images = np.array(images, dtype = np.float32)\n",
    "train_features = images[:, :15].reshape (-1, (28 * 28))\n",
    "print (train_features.shape)\n",
    "test_features = images[:, 15:30].reshape (-1, (28 * 28))\n",
    "print (test_features.shape)\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "knn = cv2.ml.KNearest_create()\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "result = model.predict(test_features)\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "print ('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with MEAN NORMALIZATION\n",
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "print (mnist.shape)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype = np.float32)\n",
    "train_features = images[:, :50].reshape (-1, (20 * 20))\n",
    "print (train_features.shape)\n",
    "test_features = images[:, 50:100].reshape (-1, (20 * 20))\n",
    "print (test_features.shape)\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "train_features -= np.mean(train_features, axis = 0)\n",
    "test_features -= np.mean(train_features, axis = 0)\n",
    "knn = cv2.ml.KNearest_create()\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "result = model.predict(test_features)\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "print ('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "print (mnist.shape)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype = np.float32)\n",
    "train_features = images[:, :50].reshape (-1, (20 * 20))\n",
    "print (train_features.shape)\n",
    "test_features = images[:, 50:100].reshape (-1, (20 * 20))\n",
    "print (test_features.shape)\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "knn = cv2.ml.KNearest_create()\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "result = model.predict(test_features)\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "print ('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype = np.float32)\n",
    "\n",
    "images.shape\n",
    "\n",
    "train_features = images.reshape (-1, (20 * 20))\n",
    "\n",
    "train_features.shape\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "train_features = images[:, :50].reshape (-1, (20 * 20))\n",
    "test_features = images[:, 50:100].reshape (-1, (20 * 20))\n",
    "\n",
    "pca.fit(train_features)\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()\n",
    "\n",
    "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None, svd_solver='auto', tol=0.0, whiten=False)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "\n",
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype = np.float32)\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(train_features)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "# model = cv2.ml.SVM_create()\n",
    "# model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "# model.setC(2.67)\n",
    "# model.setGamma(5.383)\n",
    "# model.setType(cv2.ml.SVM_C_SVC)\n",
    "# model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "result = model.predict(test_features)\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "\n",
    "\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "print ('Accuracy : {}'.format(accuracy))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()\n",
    "\n",
    "pca = PCA(n_components=images.shape[1])\n",
    "\n",
    "train_features = images[:, :50].reshape (-1, (20 * 20))\n",
    "test_features = images[:, 50:100].reshape (-1, (20 * 20))\n",
    "\n",
    "pca.fit(train_features)\n",
    "\n",
    "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None, svd_solver='auto', tol=0.0, whiten=False)\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA mnist\n",
    "\n",
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "print(mnist.shape)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype=np.float32)\n",
    "\n",
    "pca = PCA(n_components = images.shape[1])\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "train_features = images[:, :50].reshape(-1, (20 * 20))\n",
    "test_features = images[:, 50:100].reshape(-1, (20 * 20))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "pca.fit(train_features)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)\n",
    "\n",
    "#check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "#convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "#count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "#compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA fashion\n",
    "\n",
    "fashion = cv2.imread('../datasets/fashion.png', 0)\n",
    "print(mnist.shape)\n",
    "images = [np.hsplit(row, 30) for row in np.vsplit(fashion, 30)]\n",
    "images = np.array(images, dtype=np.float32)\n",
    "\n",
    "pca = PCA(n_components = images.shape[1])\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "train_features = images[:, :15].reshape(-1, (28 * 28))\n",
    "test_features = images[:, 15:30].reshape(-1, (28 * 28))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "pca.fit(train_features)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)\n",
    "\n",
    "#check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "#convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "#count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "#compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA mnist with SVM\n",
    "\n",
    "mnist = cv2.imread('../datasets/digits.png', 0)\n",
    "print(mnist.shape)\n",
    "images = [np.hsplit(row, 100) for row in np.vsplit(mnist, 50)]\n",
    "images = np.array(images, dtype=np.float32)\n",
    "\n",
    "pca = PCA(n_components = images.shape[1])\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "train_features = images[:, :50].reshape(-1, (20 * 20))\n",
    "test_features = images[:, 50:100].reshape(-1, (20 * 20))\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "pca.fit(train_features)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "ret, result, neighbors, dist = knn.findNearest(test_features, 3)\n",
    "\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "#check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "#convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "#count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "#compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
